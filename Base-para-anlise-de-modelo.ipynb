{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a6eb882-0e4a-4421-9269-efb0b6f7d18e",
   "metadata": {},
   "source": [
    "# Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19268fee-cd45-4bb2-8297-19ade5367073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import joblib\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, \n",
    "                             roc_curve, roc_auc_score, precision_recall_curve, classification_report, auc,confusion_matrix)\n",
    "\n",
    "## Coloque os seus dados já tratados aqui\n",
    "data = pd.read_csv('dados_tratados.csv', index_col='Unnamed: 0')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2bced9-ce63-4884-a387-b05db52f206b",
   "metadata": {},
   "source": [
    "# Balanceando os target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68bbd88-1e26-4718-905f-af3a9e74dc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando os atributos e os target\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Criando o objeto de oversampling\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Aplicando o oversampling para balancear as classes\n",
    "X_res, y_res = ros.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd74fad-8b12-4a9a-ae2d-11cb05a35850",
   "metadata": {},
   "source": [
    "# Separando em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b59703-245c-4567-ba23-f7adece5947e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando entre treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_res, y_res,\n",
    "    test_size=0.3,         \n",
    "    random_state=42,       \n",
    "    stratify=y_res              \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1457fa-5400-4ae8-b238-d43d648e4c4e",
   "metadata": {},
   "source": [
    "# Aplicando GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d605151-7ff0-4e23-90da-60f837f6beea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o modelo RandomForest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Definir a grade de parâmetros (grid) para o RandomForest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Configurar o GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=10,                \n",
    "    scoring='accuracy',  \n",
    "    n_jobs=-1,           \n",
    "    verbose=1            \n",
    ")\n",
    "\n",
    "# Aplicar o GridSearchCV aos dados de treino\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Exibir os melhores parâmetros e a melhor acurácia encontrada na validação\n",
    "print(\"Melhores parâmetros encontrados:\", grid_search.best_params_)\n",
    "print(\"Melhor acurácia na validação cruzada:\", grid_search.best_score_)\n",
    "\n",
    "# Avaliar o modelo selecionado no conjunto de teste\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"\\nAcurácia no conjunto de teste:\", test_accuracy)\n",
    "print(\"\\nRelatório de Classificação no conjunto de teste:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e29eedf-8e70-4fee-a61e-c3b4a9b21f41",
   "metadata": {},
   "source": [
    "# Gerando gráfico de Análise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a68b42-fceb-4d78-ad94-8920dda6b7c5",
   "metadata": {},
   "source": [
    "## Matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caecc8ad-0f12-40cb-a5bb-6f6a0a1c721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a matriz de confusão\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Define os rótulos customizados para as classes:\n",
    "# 0 --> \"não fechou o gap\"\n",
    "# 1 --> \"fechou o gap\"\n",
    "classes = ['Não fechou o GAP', 'Fechou o GAP']\n",
    "\n",
    "# Plota a matriz de confusão utilizando seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Valor Predito')\n",
    "plt.ylabel('Valor Verdadeiro')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5142d72f-78ce-4834-aefc-270b432d2a53",
   "metadata": {},
   "source": [
    "## Curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e15e1f-5101-426f-b88c-89b84c4a3547",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = best_model.predict_proba(X_test)\n",
    "y_scores = [x for _,x in y_scores]\n",
    "# Calcula a curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores)\n",
    "\n",
    "# Calcula a AUC (Area Under the Curve)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot da curva ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
    "         label='Curva ROC (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--',\n",
    "         label='Linha de referência (AUC = 0.5)')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de Falsos Positivos')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2995983-aa44-4e10-9bd3-db0070c6de5b",
   "metadata": {},
   "source": [
    "## Analisando distribuição da acurácia, precision e recall do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538b6a47-a1f9-45ed-ac8b-aa1e3384edcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_acuracia = []\n",
    "list_precision = []\n",
    "list_recall = []\n",
    "for x in range(1,101):\n",
    "    rf = best_model\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_res, y_res,\n",
    "    test_size=0.3,         \n",
    "    random_state=x,       \n",
    "    stratify=y_res              \n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    test_precision = precision_score(y_test, y_pred)\n",
    "    test_recall = recall_score(y_test, y_pred)\n",
    "    list_acuracia.append(test_accuracy)\n",
    "    list_precision.append(test_precision)\n",
    "    list_recall.append(test_recall)\n",
    "# Ploando o gráfico\n",
    "plt.figure(figsize = (16,9))\n",
    "plt.hist(list_acuracia, bins = [x/100 for x in range(50,101,1)], edgecolor = 'black', label = 'Acurácia', color = 'blue')\n",
    "plt.hist(list_precision, bins = [x/100 for x in range(50,101,1)], edgecolor = 'black',color = 'orange', label = 'Precision', alpha = .5)\n",
    "plt.hist(list_acuracia, bins = [x/100 for x in range(50,101,1)], edgecolor = 'black', color = 'green', label = 'Recall', alpha = .5)\n",
    "plt.title('Distribuição da acurácia do meu modelo')\n",
    "plt.ylabel('Frequência')\n",
    "plt.xlabel('Acurácia')\n",
    "plt.xticks([x/100 for x in range(50,101,1)], rotation = 'vertical')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd13fdb-434d-4200-a6f2-baa40ba41ed8",
   "metadata": {},
   "source": [
    "## Gráfico de Métricas vs Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ca00b4-a208-4c09-80b7-3044c0fdc3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter as probabilidades preditas para a classe positiva (1)\n",
    "y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calcular as métricas para diferentes thresholds\n",
    "thresholds = np.linspace(0, 1, 100)\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "for thresh in thresholds:\n",
    "    # Classifica com base no threshold atual\n",
    "    y_pred_thresh = (y_prob >= thresh).astype(int)\n",
    "    accuracy_list.append(accuracy_score(y_test, y_pred_thresh))\n",
    "    precision_list.append(precision_score(y_test, y_pred_thresh))\n",
    "    recall_list.append(recall_score(y_test, y_pred_thresh))\n",
    "    f1_list.append(f1_score(y_test, y_pred_thresh))\n",
    "\n",
    "# Plotar o gráfico de Métricas vs Threshold\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, accuracy_list, label='Acurácia', lw=2)\n",
    "plt.plot(thresholds, precision_list, label='Precisão', lw=2)\n",
    "plt.plot(thresholds, recall_list, label='Recall', lw=2)\n",
    "plt.plot(thresholds, f1_list, label='F1 Score', lw=2)\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Valor da Métrica')\n",
    "plt.title('Métricas de Classificação vs Threshold')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cfd5e5-28f7-4016-9d51-a9116058c980",
   "metadata": {},
   "source": [
    "# Analisando modelo com o Threshold em 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98db530-4aff-45f7-8aa1-ffd9f9412f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o threshold de 0.6\n",
    "threshold = 0.60\n",
    "y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "y_pred_06 = (y_prob >= threshold).astype(int)\n",
    "\n",
    "# Calculando as métricas para threshold = 0.6\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy_06 = accuracy_score(y_test, y_pred_06)\n",
    "precision_06 = precision_score(y_test, y_pred_06)\n",
    "recall_06 = recall_score(y_test, y_pred_06)\n",
    "f1_06 = f1_score(y_test, y_pred_06)\n",
    "\n",
    "print(f\"Acurácia com threshold 0.6: {accuracy_06:.2f}\")\n",
    "print(f\"Precisão com threshold 0.6: {precision_06:.2f}\")\n",
    "print(f\"Recall com threshold 0.6: {recall_06:.2f}\")\n",
    "print(f\"F1 Score com threshold 0.6: {f1_06:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b495115-9f33-42f5-9ffb-e6655c1543a0",
   "metadata": {},
   "source": [
    "## Matriz de confusão com Threshold de 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd7d113-a6e7-4ac5-9ec1-5c2ab0b20876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a matriz de confusão\n",
    "cm = confusion_matrix(y_test, y_pred_06)\n",
    "\n",
    "# Define os rótulos customizados para as classes:\n",
    "# 0 --> \"não fechou o gap\"\n",
    "# 1 --> \"fechou o gap\"\n",
    "classes = ['Não fechou o GAP', 'Fechou o GAP']\n",
    "\n",
    "# Plota a matriz de confusão utilizando seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Valor Predito')\n",
    "plt.ylabel('Valor Verdadeiro')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a7252b-c383-43dd-8315-29fa563e093c",
   "metadata": {},
   "source": [
    "# Analisando os atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6e03f5-e388-4b7c-bb81-5b25bf00f0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome colunas\n",
    "feature_names = X.columns\n",
    "# Fazer previsões e avaliar o modelo\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Acurácia do modelo:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Analisar a importância dos atributos\n",
    "importances = best_model.feature_importances_\n",
    "\n",
    "# Criar um DataFrame para exibir as importâncias de forma organizada\n",
    "df_importances = pd.DataFrame({\n",
    "    'Atributo': feature_names,\n",
    "    'Importância': importances\n",
    "}).sort_values(by='Importância', ascending=False)\n",
    "\n",
    "print(\"\\nImportância dos Atributos:\")\n",
    "print(df_importances)\n",
    "\n",
    "df_importances = df_importances.reset_index(drop=True)\n",
    "\n",
    "# Gerar um array com as posições (0, 1, 2, ..., n-1)\n",
    "posicoes = np.arange(len(df_importances))\n",
    "\n",
    "plt.figure(figsize=(16, 9))\n",
    "\n",
    "# Plota as barras usando as posições numéricas\n",
    "plt.bar(posicoes, df_importances['Importância'], color='skyblue', align='center')\n",
    "\n",
    "# Define os rótulos (xticks) usando as mesmas posições\n",
    "plt.xticks(posicoes, df_importances['Atributo'], rotation=45, ha='right')\n",
    "\n",
    "plt.title('Importância dos Atributos - Random Forest')\n",
    "plt.xlabel('Atributos')\n",
    "plt.ylabel('Importância')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64342092-9e31-49e9-8046-8efd793bcaae",
   "metadata": {},
   "source": [
    "# Exportando o modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f31696-da1a-47be-aa93-edfc2e10cea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(best_model, 'melhor_modelo_prever_se_vai_fechar_o_gap.pkl')\n",
    "print(\"Modelo exportado com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
